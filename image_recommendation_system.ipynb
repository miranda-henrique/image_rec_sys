{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d52038",
   "metadata": {},
   "source": [
    "# Building Visual Similarity based Recommendation\n",
    "\n",
    "[Source](https://www.kaggle.com/code/vikashrajluhaniwal/building-visual-similarity-based-recommendation/notebook)\n",
    "\n",
    "[Dataset](https://www.kaggle.com/datasets/vikashrajluhaniwal/fashion-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d08b55",
   "metadata": {},
   "source": [
    "### Basic Data Analysis\n",
    "#### 1.1 Importing the necessary libraries & loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "#import streamlit as st\n",
    "#use the below library while displaying the images in jupyter notebook\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df = pd.read_csv(\"./data/fashion.csv\")\n",
    "fashion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ed664",
   "metadata": {},
   "source": [
    "#### 1.2 Basic statistics - Number of products, subcategories & gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30557a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of products : \", fashion_df.shape[0])\n",
    "print(\"Total number of unique subcategories : \", fashion_df[\"SubCategory\"].nunique())\n",
    "print(\"Total number of unique gender types : \", fashion_df[\"Gender\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe6918",
   "metadata": {},
   "source": [
    "#### 1.3 Frequency of each gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904252ba",
   "metadata": {},
   "source": [
    "#### 1.4 Distribution of products gender-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.countplot(fashion_df[\"Gender\"])\n",
    "plt.title(\"Distribution of articles gender-wise\")\n",
    "plt.xlabel(\"Gender type\")\n",
    "plt.ylabel(\"Number of products\")\n",
    "plot.set_xticklabels(plot.get_xticklabels())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532e470",
   "metadata": {},
   "source": [
    "#### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "apparel_boys = fashion_df[fashion_df[\"Gender\"]==\"Boys\"]\n",
    "apparel_girls = fashion_df[fashion_df[\"Gender\"]==\"Girls\"]\n",
    "footwear_men = fashion_df[fashion_df[\"Gender\"]==\"Men\"]\n",
    "footwear_women = fashion_df[fashion_df[\"Gender\"]==\"Women\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf0e1b",
   "metadata": {},
   "source": [
    "### 3. Feature extraction using ResNet\n",
    "\n",
    "#### For Gender - Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "train_data_dir = \"./data/Footwear/Men/\"\n",
    "\n",
    "nb_train_samples = 811\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "\n",
    "def extract_features():\n",
    "    Itemcodes = []\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    model = ResNet50(include_top=False, weights='imagenet')\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    for i in generator.filenames:\n",
    "        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n",
    "    extracted_features = model.predict(generator, nb_train_samples // batch_size)\n",
    "    extracted_features = extracted_features.reshape((811, 100352))\n",
    "    \n",
    "    np.save(open('./Men_ResNet_features.npy', 'wb'), extracted_features)\n",
    "    np.save(open('./Men_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n",
    "    \n",
    "a = datetime.now()\n",
    "extract_features()\n",
    "print(\"Time taken in feature extraction\", datetime.now()-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1cd015",
   "metadata": {},
   "source": [
    "### 4. Computing the Euclidean distance and recommending similar products\n",
    "#### 4.1 Loading the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = np.load('./Men_ResNet_features.npy')\n",
    "Productids = np.load('./Men_ResNet_feature_product_ids.npy')\n",
    "men = footwear_men.copy()\n",
    "#men = pd.read_csv('./footwear_men.csv')\n",
    "df_Productids = list(men['ProductId'])\n",
    "Productids = list(Productids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0046004",
   "metadata": {},
   "source": [
    "#### 4.2 Distance computation and Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe68a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_products_cnn(product_id, num_results):\n",
    "    doc_id = Productids.index(product_id)\n",
    "    pairwise_dist = pairwise_distances(extracted_features, extracted_features[doc_id].reshape(1,-1))\n",
    "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
    "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
    "    print(\"=\"*20, \"input product image\", \"=\"*20)\n",
    "    ip_row = men[['ImageURL','ProductTitle']].loc[men['ProductId']==int(Productids[indices[0]])]\n",
    "    #print(ip_row.head())\n",
    "    for indx, row in ip_row.iterrows():\n",
    "        display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n",
    "        print('Product Title: ', row['ProductTitle'])\n",
    "    print(\"\\n\",\"=\"*20, \"Recommended products\", \"=\"*20)\n",
    "    for i in range(1,len(indices)):\n",
    "        rows = men[['ImageURL','ProductTitle']].loc[men['ProductId']==int(Productids[indices[i]])]\n",
    "        for indx, row in rows.iterrows():\n",
    "            display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n",
    "            print('Product Title: ', row['ProductTitle'])\n",
    "            print('Euclidean Distance from input image:', pdists[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameProductIds(productId):\n",
    "    return productId[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Productids = list(map(renameProductIds, Productids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dabfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_products_cnn('10037', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579b74a",
   "metadata": {},
   "source": [
    "##### **NOTE** - The above feature extraction process can be repeated for other genders (Women, Boys and Girls) as well. So let's extract for each one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb47b29",
   "metadata": {},
   "source": [
    "#### For Gender - Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c2add",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "\n",
    "#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "train_data_dir = \"./data/Footwear/Women/\"\n",
    "\n",
    "nb_train_samples = 769\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "\n",
    "def extract_features():\n",
    "    Itemcodes = []\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    model = ResNet50(include_top=False, weights='imagenet')\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    for i in generator.filenames:\n",
    "        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n",
    "    extracted_features = model.predict(generator, nb_train_samples // batch_size)\n",
    "    extracted_features = extracted_features.reshape((769, 100352))\n",
    "    \n",
    "    np.save(open('./Women_ResNet_features.npy', 'wb'), extracted_features)\n",
    "    np.save(open('./Women_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n",
    "    \n",
    "a = datetime.now()\n",
    "extract_features()\n",
    "print(\"Time taken in feature extraction\", datetime.now()-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf3ba2",
   "metadata": {},
   "source": [
    "#### For Gender - Boys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c886e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "\n",
    "#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "train_data_dir = \"./data/Apparel/Boys/\"\n",
    "\n",
    "nb_train_samples = 759\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "\n",
    "def extract_features():\n",
    "    Itemcodes = []\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    model = ResNet50(include_top=False, weights='imagenet')\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    for i in generator.filenames:\n",
    "        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n",
    "    extracted_features = model.predict(generator, nb_train_samples // batch_size)\n",
    "    extracted_features = extracted_features.reshape((759, 100352))\n",
    "    \n",
    "    np.save(open('./Boys_ResNet_features.npy', 'wb'), extracted_features)\n",
    "    np.save(open('./Boys_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n",
    "    \n",
    "a = datetime.now()\n",
    "extract_features()\n",
    "print(\"Time taken in feature extraction\", datetime.now()-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bc6fa",
   "metadata": {},
   "source": [
    "#### For Gender - Girls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "\n",
    "#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "train_data_dir = \"./data/Apparel/Girls/\"\n",
    "\n",
    "nb_train_samples = 567\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "\n",
    "def extract_features():\n",
    "    Itemcodes = []\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    model = ResNet50(include_top=False, weights='imagenet')\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    for i in generator.filenames:\n",
    "        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n",
    "    extracted_features = model.predict(generator, nb_train_samples // batch_size)\n",
    "    extracted_features = extracted_features.reshape((567, 100352))\n",
    "    \n",
    "    np.save(open('./Girls_ResNet_features.npy', 'wb'), extracted_features)\n",
    "    np.save(open('./Girls_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n",
    "    \n",
    "a = datetime.now()\n",
    "extract_features()\n",
    "print(\"Time taken in feature extraction\", datetime.now()-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a74c2",
   "metadata": {},
   "source": [
    "### 5. Deploying the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e92e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boys_extracted_features = np.load('./Boys_ResNet_features.npy')\n",
    "boys_Productids = np.load('./Boys_ResNet_feature_product_ids.npy')\n",
    "girls_extracted_features = np.load('./Girls_ResNet_features.npy')\n",
    "girls_Productids = np.load('./Girls_ResNet_feature_product_ids.npy')\n",
    "men_extracted_features = np.load('./Men_ResNet_features.npy')\n",
    "men_Productids = np.load('./Men_ResNet_feature_product_ids.npy')\n",
    "women_extracted_features = np.load('./Women_ResNet_features.npy')\n",
    "women_Productids = np.load('./Women_ResNet_feature_product_ids.npy')\n",
    "fashion_df[\"ProductId\"] = fashion_df[\"ProductId\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_products_cnn(product_id, num_results):\n",
    "    if(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Boys\"):\n",
    "        extracted_features = boys_extracted_features\n",
    "        Productids = list(map(renameProductIds, boys_Productids))\n",
    "    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Girls\"):\n",
    "        extracted_features = girls_extracted_features\n",
    "        Productids = list(map(renameProductIds, girls_Productids))\n",
    "    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Men\"):\n",
    "        extracted_features = list(map(renameProductIds, men_extracted_features))\n",
    "        Productids = men_Productids\n",
    "    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Women\"):\n",
    "        extracted_features = women_extracted_features\n",
    "        Productids = list(map(renameProductIds, women_Productids))\n",
    "    Productids = list(Productids)\n",
    "    doc_id = Productids.index(product_id)\n",
    "    pairwise_dist = pairwise_distances(extracted_features, extracted_features[doc_id].reshape(1,-1))\n",
    "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
    "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
    "    print(\"=\"*20, \"input product details\", \"=\"*20)\n",
    "    ip_row = fashion_df[['ImageURL','ProductTitle']].loc[fashion_df['ProductId']==Productids[indices[0]]]\n",
    "    for indx, row in ip_row.iterrows():\n",
    "        display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n",
    "        print('Product Title: ', row['ProductTitle'])\n",
    "    print(\"\\n\",\"=\"*20, \"Recommended products\", \"=\"*20)\n",
    "    for i in range(1,len(indices)):\n",
    "        rows = fashion_df[['ImageURL','ProductTitle']].loc[fashion_df['ProductId']==Productids[indices[i]]]\n",
    "        for indx, row in rows.iterrows():\n",
    "            display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n",
    "            print('Product Title: ', row['ProductTitle'])\n",
    "            print('Euclidean Distance from input image:', pdists[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_products_cnn('21030', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07779b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_products_cnn('18181', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898db53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
